{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os package reports 28 available cores\n",
      "multiprocessing package reports 28 available cores\n",
      "Slurm reports 1 available cores\n"
     ]
    }
   ],
   "source": [
    "# Python program to explain os.cpu_count() method   \n",
    "   \n",
    "import os \n",
    "import multiprocessing as mp\n",
    "\n",
    "def report_cores(name,count):\n",
    "     print(\"{0} reports {1} available cores\".format(name,count))  \n",
    "\n",
    "report_cores(\"os package\",os.cpu_count())\n",
    "report_cores(\"multiprocessing package\",mp.cpu_count())\n",
    "report_cores(\"Slurm\",os.getenv('SLURM_NTASKS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "importing socket on engine(s)\n",
      "['iris-003', 'iris-004']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import ipyparallel as ipp\n",
    "c = ipp.Client(profile='job_{0}'.format(os.getenv('SLURM_JOB_ID')))\n",
    "views = c[:]\n",
    "print(c.ids)\n",
    "with views.sync_imports():\n",
    "     import socket\n",
    "\n",
    "results = views.apply_sync(socket.gethostname)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{0}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 13 18:38:50 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:1D:00.0 Off |                    0 |\r\n",
      "| N/A   36C    P0    57W / 300W |    316MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPC_SCHOOL_ENV_IPYPARALLEL_CUDA",
   "language": "python",
   "name": "hpc_school_env_ipyparallel_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
